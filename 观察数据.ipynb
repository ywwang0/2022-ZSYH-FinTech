{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82fb56b-1e60-4630-ab6f-a187801a9485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据的数据大小为：(40000, 51)\n",
      "测试A榜的数据大小为：(12000, 50)\n",
      "Remove feature AGN_CNT_RCT_12_MON!\n",
      "Remove feature AGN_CUR_YEAR_AMT!\n",
      "Remove feature AGN_CUR_YEAR_WAG_AMT!\n",
      "Remove feature MON_12_CUST_CNT_PTY_ID!\n",
      "Remove feature CUR_YEAR_PUB_TO_PRV_TRX_PTY_CNT!\n",
      "数值型特征有41个， 类别型特征有3个\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 读取训练数据和测试数据\n",
    "df_train = pd.read_excel('train.xlsx')\n",
    "df_test = pd.read_excel('test_A榜.xlsx')\n",
    "\n",
    "# 打印数据的尺寸, 一共有49个特征\n",
    "print(f\"训练数据的数据大小为：{df_train.shape}\")\n",
    "print(f\"测试A榜的数据大小为：{df_test.shape}\")\n",
    "\n",
    "def count_q_and_nan(df,feature,ratio=0.5):\n",
    "    \"\"\"\n",
    "    ratio是？和nan数据加起来数量与总数量比例，控制特征的噪音不能太多\n",
    "    越小越严格，剔除的特征越多\n",
    "    \"\"\"\n",
    "    total_invalid_num = (df.shape[0]-sum(df[feature].value_counts()))+df[feature].value_counts()[\"?\"]\n",
    "    if total_invalid_num/df.shape[0] > ratio:\n",
    "        print(f\"Remove feature {feature}!\")\n",
    "        df.drop([feature],inplace=True,axis = 1)\n",
    "        return feature\n",
    "\n",
    "# CNT代表计数\n",
    "\n",
    "feature_info = {\n",
    "    'AGN_CNT_RCT_12_MON':'float',\n",
    "    'ICO_CUR_MON_ACM_TRX_TM':'float',\n",
    "    'NB_RCT_3_MON_LGN_TMS_AGV':'float',\n",
    "    'AGN_CUR_YEAR_AMT':'float',\n",
    "    'AGN_CUR_YEAR_WAG_AMT':'float',\n",
    "    'AGN_AGR_LATEST_AGN_AMT':'float',\n",
    "    'ICO_CUR_MON_ACM_TRX_AMT':'float',\n",
    "    'COUNTER_CUR_YEAR_CNT_AMT':'float',\n",
    "    'PUB_TO_PRV_TRX_AMT_CUR_YEAR':'float',\n",
    "    'MON_12_EXT_SAM_TRSF_IN_AMT':'float',\n",
    "    'MON_12_EXT_SAM_TRSF_OUT_AMT':'float',\n",
    "    'MON_12_EXT_SAM_NM_TRSF_OUT_CNT':'float',\n",
    "    'MON_12_EXT_SAM_AMT':'float',\n",
    "    'CUR_MON_EXT_SAM_CUST_TRSF_IN_AMT':'float',\n",
    "    'CUR_MON_EXT_SAM_CUST_TRSF_OUT_AMT':'float',\n",
    "    'MON_12_CUST_CNT_PTY_ID':'str',\n",
    "    'MON_12_TRX_AMT_MAX_AMT_PCTT':'float',\n",
    "    'CUR_YEAR_MON_AGV_TRX_CNT':'float',\n",
    "    'MON_12_AGV_TRX_CNT':'float',\n",
    "    'MON_12_ACM_ENTR_ACT_CNT':'float',\n",
    "    'MON_12_AGV_ENTR_ACT_CNT':'float',\n",
    "    'MON_12_ACM_LVE_ACT_CNT':'float',\n",
    "    'MON_12_AGV_LVE_ACT_CNT':'float',\n",
    "    'CUR_YEAR_PUB_TO_PRV_TRX_PTY_CNT':'float',\n",
    "    'MON_6_50_UP_ENTR_ACT_CNT':'float',\n",
    "    'MON_6_50_UP_LVE_ACT_CNT':'float',\n",
    "    'CUR_YEAR_COUNTER_ENCASH_CNT':'float',\n",
    "    'MON_12_ACT_OUT_50_UP_CNT_PTY_QTY':'float',\n",
    "    'MON_12_ACT_IN_50_UP_CNT_PTY_QTY':'float',\n",
    "    'LAST_12_MON_COR_DPS_TM_PNT_BAL_PEAK_VAL':'float',\n",
    "    'LAST_12_MON_COR_DPS_DAY_AVG_BAL':'float',\n",
    "    'CUR_MON_COR_DPS_MON_DAY_AVG_BAL':'float',\n",
    "    'CUR_YEAR_COR_DMND_DPS_DAY_AVG_BAL':'float',\n",
    "    'CUR_YEAR_COR_DPS_YEAR_DAY_AVG_INCR':'float',\n",
    "    'LAST_12_MON_DIF_NM_MON_AVG_TRX_AMT_NAV':'float',\n",
    "    'LAST_12_MON_MON_AVG_TRX_AMT_NAV':'float',\n",
    "    'COR_KEY_PROD_HLD_NBR':'float',\n",
    "    'CUR_YEAR_MID_BUS_INC':'float',\n",
    "    'AI_STAR_SCO':'float',\n",
    "    'WTHR_OPN_ONL_ICO':'str',\n",
    "    'EMP_NBR':'float',\n",
    "    'REG_CPT':'float',\n",
    "    'SHH_BCK':'float',\n",
    "    'HLD_DMS_CCY_ACT_NBR':'float',\n",
    "    'REG_DT':'float',\n",
    "    'LGP_HLD_CARD_LVL':'str',\n",
    "    'OPN_TM':'float',\n",
    "    'NB_CTC_HLD_IDV_AIO_CARD_SITU':'str',\n",
    "    'HLD_FGN_CCY_ACT_NBR':'float',\n",
    "}\n",
    "\n",
    "removed_features = []\n",
    "for f in feature_info.keys():\n",
    "    removed_features.append(count_q_and_nan(df_train,f,ratio=0.5))\n",
    "\n",
    "removed_features = [i for i in removed_features if i != None]\n",
    "for rf in removed_features:\n",
    "    del feature_info[rf]\n",
    "\n",
    "# 发现有4个类别特征\n",
    "class_feature_name = []\n",
    "value_feature_name = []\n",
    "for feature in feature_info.keys():\n",
    "    if feature_info[feature] =='float':\n",
    "        value_feature_name.append(feature)\n",
    "    else:\n",
    "        class_feature_name.append(feature)\n",
    "print(f\"数值型特征有{len(value_feature_name)}个， 类别型特征有{len(class_feature_name)}个\")\n",
    "\n",
    "# 数据处理阶段\n",
    "# 不知道用平均数好还是中位数好，这里先用平均数\n",
    "def replace_q_with_average(df, feature):\n",
    "    if '?' not in list(df[feature]):\n",
    "        # print(f\"{feature} do not contain ?\")\n",
    "        return df\n",
    "    else:  \n",
    "        values = [i for i in df[feature] if i != '?']\n",
    "        df[feature].replace(\"?\", sum(values)/len(values), inplace = True)\n",
    "        \n",
    "def replace_q_with_G(df, feature):\n",
    "    if '?' not in list(df[feature]):\n",
    "        # print(f\"{feature} do not contain ?\")\n",
    "        return df\n",
    "    else:\n",
    "        df[feature].replace(\"?\", \"G\", inplace = True)\n",
    "        \n",
    "def replace_nan_with_N(df, feature):\n",
    "    df[feature].replace(np.nan, \"N\", inplace = True)\n",
    "    \n",
    "\n",
    "for feature, kind in feature_info.items():\n",
    "    if kind =='float':\n",
    "        replace_q_with_average(df_train, feature = feature)\n",
    "    else:\n",
    "        replace_q_with_G(df_train, feature = feature)\n",
    "        replace_nan_with_N(df_train, feature = feature)\n",
    "\n",
    "# 将类型特征独热编码\n",
    "\n",
    "def change_to_onehot(df, feature):\n",
    "    if feature not in df.columns:\n",
    "        return df\n",
    "    df_onehot = pd.get_dummies(df[feature])\n",
    "    new_columns = [feature+'_'+i for i in df_onehot.columns]\n",
    "    df_onehot.columns = new_columns\n",
    "    df_contact = pd.concat([df,df_onehot],axis=1)\n",
    "    df_contact.drop([feature], axis = 1, inplace = True)\n",
    "    return df_contact\n",
    "for f in class_feature_name:\n",
    "    df_train = change_to_onehot(df_train, f)\n",
    "\n",
    "\n",
    "\n",
    "x_train, y_train = df_train.drop(['CUST_UID','LABEL'],axis=1), df_train['LABEL']\n",
    "\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold,GridSearchCV,cross_val_score\n",
    "\n",
    "random_seed = 15\n",
    "\n",
    "parameters = {\n",
    "    'max_depth': [2,4,6,8,10,12,14],\n",
    "    'num_leaves': [ 15, 28, 29, 30, 31,33],\n",
    "    # 'min_child_samples': [18,19,20,21,22],\n",
    "    # 'min_child_weight':[0.001,0.002],\n",
    "    # 'feature_fraction': [0.85, 0.9, 0.95,1.0],\n",
    "    #  'bagging_fraction': [0.8,0.9,1],\n",
    "    #  'bagging_freq': [2,3,4],\n",
    "    #  'reg_alpha' :[0.001,0.01,0.1,1],\n",
    "    #   'reg_lambda' : [0.001,0.01,0.1,1,10],\n",
    "}\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=random_seed)\n",
    "gbm = lgb.LGBMClassifier(objective = 'binary',\n",
    "                         is_unbalance = True,\n",
    "                         metric = 'binary_logloss,auc',\n",
    "                         learning_rate = 0.1,\n",
    "                         # num_iterations = 200,   \n",
    "                        )\n",
    "\n",
    "gsearch = GridSearchCV(gbm, param_grid=parameters, scoring='roc_auc', cv=kf, n_jobs=-1)\n",
    "gsearch.fit(x_train, y_train)\n",
    "print('参数的最佳取值:{0}'.format(gsearch.best_params_))\n",
    "print('最佳模型得分:{0}'.format(gsearch.best_score_))\n",
    "# print(gsearch.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41708bc9-3901-4227-9a18-824e5e5eb34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e611b8b8-93a1-4d26-8ed9-63dd40a5d56d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f45937856810>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc9e4e3-d38c-40fb-98fd-70e18467ae6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
